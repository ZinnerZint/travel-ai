import streamlit as st
import google.generativeai as genai
from rag import load_data, search_relevant_places

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å
st.set_page_config(page_title="TripTech AI", page_icon="üå¥")
st.title("üå¥ TripTech AI")

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Excel
df = load_data()

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
user_input = st.chat_input("‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢...")

if user_input:
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å Excel
    results = search_relevant_places(df, user_input)
    context = "\n".join(
        f"- {r['‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà']} ({r['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']}): {r['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢']}"
        for r in results
    )

    # ‡∏£‡∏ß‡∏°‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
    history_text = ""
    for i, msg in enumerate(st.session_state.messages):
        if i == 0 and msg["role"] == "assistant":
            continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏ã‡πâ‡∏≥
        role = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ" if msg["role"] == "user" else "AI"
        history_text += f"{role}: {msg['content']}\n"

    # ‡∏£‡∏ß‡∏° prompt
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏Å‡∏î‡πå‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢
‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:
{history_text}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:
{context}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å
"""

    try:
        model = genai.GenerativeModel(model_name="gemini-2.0-flash-lite")  # ‡πÉ‡∏ä‡πâ Gemini Pro
        response = model.generate_content(prompt)
        bot_reply = response.text
    except Exception as e:
        bot_reply = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å Gemini: {e}"

    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI
    st.chat_message("assistant").markdown(bot_reply)
    st.session_state.messages.append({"role": "assistant", "content": bot_reply})
