import streamlit as st
import google.generativeai as genai
from rag import load_data, search_relevant_places
from login import login

# --- PAGE CONFIG ---
st.set_page_config(page_title="TripTech AI", page_icon="üå¥", layout="centered")

# --- AUTHENTICATION ---
if not login():
    st.stop()

# --- MAIN APP ---
st.title("üå¥ TripTech AI")

# Load data
df = load_data()

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# User input
if user_input := st.chat_input("‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Search for relevant places
    results = search_relevant_places(df, user_input)
    context = "\n".join(
        f"- {r['‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà']} ({r['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']}): {r['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢']}\n‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {r.get('‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û', '')}"
        for r in results
    )

    # Build conversation history for the prompt
    history_text = ""
    for msg in st.session_state.messages:
        role = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ" if msg["role"] == "user" else "AI"
        history_text += f"{role}: {msg['content']}\n"

    # Create the prompt for the generative model
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏Å‡∏î‡πå‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£
‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤:
{history_text}
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:
{context}
‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
- ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
- ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞/‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ"
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
- ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ô‡∏±‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢
"""

    # Generate response from the model
    try:
        model = genai.GenerativeModel(model_name="gemini-pro")
        response = model.generate_content(prompt)
        bot_reply = response.text
    except Exception as e:
        bot_reply = f"‚ùå ‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"
        st.error(bot_reply)

    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": bot_reply})
    with st.chat_message("assistant"):
        st.markdown(bot_reply)

        # Display images if available in the search results
        for r in results:
            if '‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û' in r and isinstance(r['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'], str) and r['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'].startswith("http"):
                st.image(r['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'], caption=r['‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà'], use_container_width=True)
                if '‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï' in r and isinstance(r['‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï'], str) and r['‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï'].strip():
                    st.markdown(
                        f"<div style='font-size: 0.8em; color: gray; text-align: right;'>üì∏ ‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï: {r['‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï']}</div>",
                        unsafe_allow_html=True,
                    )
